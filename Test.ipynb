{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64849b9-3eaf-4270-8fc0-e4fd4bc21d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a8fef3-543c-42a3-8333-7dc88fba84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def measure_inference_time(model: nn.Module, device, loader, n_batches=10):\n",
    "    model.eval()\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    start = time.time()\n",
    "    it = iter(loader)\n",
    "    for _ in range(min(n_batches, len(loader))):\n",
    "        try:\n",
    "            x, _ = next(it)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    end = time.time()\n",
    "    return (end - start) / max(1, min(n_batches, len(loader)))\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, num_classes, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(last, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_shape=(1, 28, 28), num_classes=10, base_channels=32, fc_units=100):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # calcula o tamanho da saída após convolução\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, *input_shape)  # ex: (1, 1, 28, 28) para MNIST\n",
    "            conv_out = self.conv(dummy)\n",
    "            conv_out_dim = conv_out.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_dim, fc_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_units, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)  # achata\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, device, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def objective_multi(trial, args, train_loader, val_loader, device):\n",
    "    model_type = trial.suggest_categorical('model_type', ['mlp', 'cnn'])\n",
    "\n",
    "    if model_type == 'mlp':\n",
    "        n_layers = trial.suggest_int('n_layers', 1, 4)\n",
    "        hidden_sizes = [trial.suggest_int(f'n_units_l{i}', 32, 512) for i in range(n_layers)]\n",
    "        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    else:\n",
    "        base_channels = trial.suggest_categorical('base_channels', [16, 32, 64])\n",
    "        num_conv_layers = trial.suggest_int('num_conv_layers', 1, 3)\n",
    "        fc_units = trial.suggest_int('fc_units', 64, 512)\n",
    "        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "\n",
    "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "    epochs = args.epochs_per_trial\n",
    "\n",
    "    if model_type == 'mlp':\n",
    "        example_x, _ = next(iter(train_loader))\n",
    "        input_dim = int(np.prod(example_x.shape[1:]))\n",
    "        num_classes = len(train_loader.dataset.classes) if hasattr(train_loader.dataset, 'classes') else 10\n",
    "        model = SimpleMLP(input_dim, hidden_sizes, num_classes, dropout)\n",
    "    else:\n",
    "        in_ch = train_loader.dataset[0][0].shape[0]\n",
    "        num_classes = len(train_loader.dataset.classes) if hasattr(train_loader.dataset, 'classes') else 10\n",
    "        input_shape = train_loader.dataset[0][0].shape  # exemplo: torch.Size([1, 28, 28])\n",
    "        num_classes = len(train_loader.dataset.classes) if hasattr(train_loader.dataset, 'classes') else 10\n",
    "        \n",
    "        model = SimpleCNN(input_shape, num_classes, base_channels, fc_units)\n",
    "\n",
    "    device = device\n",
    "    model.to(device)\n",
    "\n",
    "    params = count_parameters(model)\n",
    "\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    start_time = time.time()\n",
    "    for ep in range(epochs):\n",
    "        train_one_epoch(model, device, train_loader, optimizer, criterion)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    acc = evaluate(model, device, val_loader)\n",
    "\n",
    "    inf_time = measure_inference_time(model, device, val_loader, n_batches=5)\n",
    "\n",
    "    return -acc, train_time, float(params)\n",
    "\n",
    "\n",
    "def objective_weighted(trial, args, train_loader, val_loader, device):\n",
    "    res = objective_multi(trial, args, train_loader, val_loader, device)\n",
    "    neg_acc, train_time, params = res\n",
    "    acc = -neg_acc\n",
    "    acc_norm = acc  # já entre 0 e 1\n",
    "    time_norm = train_time / (args.max_time_hint if args.max_time_hint > 0 else 100.0)\n",
    "    params_norm = params / (args.max_params_hint if args.max_params_hint > 0 else 1e6)\n",
    "    score = -(args.w_acc * acc_norm) + args.w_time * time_norm + args.w_params * params_norm\n",
    "    return float(score)\n",
    "\n",
    "def get_dataloaders(dataset_name, batch_size):\n",
    "    if dataset_name == 'mnist':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "        test = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "        n = len(train)\n",
    "        n_val = int(0.1 * n)\n",
    "        n_train = n - n_val\n",
    "        train_set, val_set = torch.utils.data.random_split(train, [n_train, n_val])\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    elif dataset_name == 'cifar10':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        train = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "        test = datasets.CIFAR10('./data', train=False, download=True, transform=transform)\n",
    "        n = len(train)\n",
    "        n_val = int(0.1 * n)\n",
    "        n_train = n - n_val\n",
    "        train_set, val_set = torch.utils.data.random_split(train, [n_train, n_val])\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Dataset não suportado no exemplo. Forneça seu DataLoader customizado.')\n",
    "\n",
    "\n",
    "def run_search(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Usando device: {device}\")\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(args.dataset, batch_size=64)\n",
    "\n",
    "    if args.mode == 'pareto':\n",
    "        study = optuna.create_study(directions=[\"minimize\", \"minimize\", \"minimize\"])  # [-acc, time, params]\n",
    "        objective = lambda trial: objective_multi(trial, args, train_loader, val_loader, device)\n",
    "    else:\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        objective = lambda trial: objective_weighted(trial, args, train_loader, val_loader, device)\n",
    "\n",
    "    print(\"Iniciando busca...\")\n",
    "    study.optimize(objective, n_trials=args.n_trials)\n",
    "\n",
    "    if args.mode == 'pareto':\n",
    "        print(\"Fronteira de Pareto encontrada (objetivos: -acc, time(s), params):\")\n",
    "        for t in study.best_trials:\n",
    "            print(t.values, t.params)\n",
    "    else:\n",
    "        print(\"Melhor trial (score ponderado):\")\n",
    "        print(study.best_trial.value, study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a35bf4-46f6-4146-af0c-ec825786dc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-30 00:49:57,613] A new study created in memory with name: no-name-d13c3867-1de9-43eb-84f8-82152d07ddfa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando device: cpu\n",
      "Iniciando busca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pdani\\AppData\\Local\\Temp\\ipykernel_2600\\4170817445.py:112: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)\n",
      "[I 2025-08-30 00:51:13,579] Trial 0 finished with values: [-0.9756666666666667, 74.36169624328613, 1759570.0] and parameters: {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 1, 'fc_units': 280, 'dropout': 0.20314273690252904, 'lr': 0.008361951953659602, 'batch_size': 32, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 00:51:51,705] Trial 1 finished with values: [-0.9731666666666666, 36.919607400894165, 435318.0] and parameters: {'model_type': 'mlp', 'n_layers': 2, 'n_units_l0': 450, 'n_units_l1': 178, 'dropout': 0.23228936881575785, 'lr': 0.0005512412046334231, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 00:53:17,228] Trial 2 finished with values: [-0.9828333333333333, 83.90655469894409, 1941777.0] and parameters: {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 2, 'fc_units': 309, 'dropout': 0.21845240028006596, 'lr': 0.0023806116970756367, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 00:53:51,540] Trial 3 finished with values: [-0.973, 33.15312886238098, 380020.0] and parameters: {'model_type': 'mlp', 'n_layers': 1, 'n_units_l0': 478, 'dropout': 0.00799212280636924, 'lr': 0.008718214465614169, 'batch_size': 32, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 00:54:43,479] Trial 4 finished with values: [-0.98, 50.51221418380737, 1356527.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 3, 'fc_units': 431, 'dropout': 0.41848214949041296, 'lr': 0.005855354974008415, 'batch_size': 64, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 00:55:20,317] Trial 5 finished with values: [-0.7546666666666667, 35.666013956069946, 272955.0] and parameters: {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 104, 'n_units_l1': 356, 'n_units_l2': 257, 'n_units_l3': 232, 'dropout': 0.2451612545089994, 'lr': 0.0003978919419980891, 'batch_size': 128, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 00:56:04,042] Trial 6 finished with values: [-0.9751666666666666, 42.369699001312256, 211019.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 2, 'fc_units': 67, 'dropout': 0.048199285791166835, 'lr': 0.0002869529650300838, 'batch_size': 32, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 00:58:58,055] Trial 7 finished with values: [-0.9816666666666667, 171.70932006835938, 6190265.0] and parameters: {'model_type': 'cnn', 'base_channels': 64, 'num_conv_layers': 3, 'fc_units': 493, 'dropout': 0.38132488964674344, 'lr': 0.0012733530236884929, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 00:59:44,720] Trial 8 finished with values: [-0.9648333333333333, 45.28686761856079, 711392.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 3, 'fc_units': 226, 'dropout': 0.40115680142022103, 'lr': 0.0014693819263513566, 'batch_size': 128, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:00:55,659] Trial 9 finished with values: [-0.9848333333333333, 69.28945541381836, 1533382.0] and parameters: {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 1, 'fc_units': 244, 'dropout': 0.17163586037537965, 'lr': 0.030398468953306754, 'batch_size': 32, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:01:41,501] Trial 10 finished with values: [-0.9846666666666667, 44.468268394470215, 613835.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 2, 'fc_units': 195, 'dropout': 0.14128024841085507, 'lr': 0.03108445617977969, 'batch_size': 128, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:02:27,537] Trial 11 finished with values: [-0.9475, 44.65125775337219, 639011.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 1, 'fc_units': 203, 'dropout': 0.27143134220086385, 'lr': 0.000678535331964409, 'batch_size': 32, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:04:15,264] Trial 12 finished with values: [-0.9811666666666666, 105.75507140159607, 1005050.0] and parameters: {'model_type': 'cnn', 'base_channels': 64, 'num_conv_layers': 1, 'fc_units': 80, 'dropout': 0.39336312635361004, 'lr': 0.0016512608877864655, 'batch_size': 128, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:04:54,701] Trial 13 finished with values: [-0.9676666666666667, 38.2529456615448, 264791.0] and parameters: {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 77, 'n_units_l1': 386, 'n_units_l2': 208, 'n_units_l3': 428, 'dropout': 0.06558288123757805, 'lr': 0.0002782484083297675, 'batch_size': 32, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:05:34,468] Trial 14 finished with values: [-0.8888333333333334, 38.604992151260376, 614119.0] and parameters: {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 366, 'n_units_l1': 511, 'n_units_l2': 175, 'n_units_l3': 267, 'dropout': 0.3378868527130405, 'lr': 0.0007037742490461218, 'batch_size': 64, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:08:15,198] Trial 15 finished with values: [-0.983, 158.5953290462494, 4043360.0] and parameters: {'model_type': 'cnn', 'base_channels': 64, 'num_conv_layers': 2, 'fc_units': 322, 'dropout': 0.2116448183946288, 'lr': 0.0023117891111118266, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:09:19,889] Trial 16 finished with values: [-0.9848333333333333, 63.15505576133728, 1187817.0] and parameters: {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 1, 'fc_units': 189, 'dropout': 0.30099354796525535, 'lr': 0.06446709015350537, 'batch_size': 128, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:09:56,907] Trial 17 finished with values: [-0.9611666666666666, 35.866156339645386, 151451.0] and parameters: {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 84, 'n_units_l1': 156, 'n_units_l2': 123, 'n_units_l3': 395, 'dropout': 0.22566540796955625, 'lr': 0.0007050544388673726, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:11:06,082] Trial 18 finished with values: [-0.9585, 67.4961326122284, 2130267.0] and parameters: {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 2, 'fc_units': 339, 'dropout': 0.11482025999502099, 'lr': 0.0009246987769235637, 'batch_size': 32, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:11:38,804] Trial 19 finished with values: [-0.9735, 31.6168794631958, 408120.0] and parameters: {'model_type': 'mlp', 'n_layers': 2, 'n_units_l0': 394, 'n_units_l1': 244, 'dropout': 0.36210503020131196, 'lr': 0.03314067991346989, 'batch_size': 64, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:13:43,570] Trial 20 finished with values: [-0.9731666666666666, 122.81666994094849, 2951075.0] and parameters: {'model_type': 'cnn', 'base_channels': 64, 'num_conv_layers': 1, 'fc_units': 235, 'dropout': 0.35822404542386393, 'lr': 0.009617808370151928, 'batch_size': 128, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:14:31,756] Trial 21 finished with values: [-0.9785, 46.76976013183594, 834125.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 2, 'fc_units': 265, 'dropout': 0.2086801244033128, 'lr': 0.00029865408204274264, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:15:11,495] Trial 22 finished with values: [-0.9626666666666667, 38.72250556945801, 544263.0] and parameters: {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 464, 'n_units_l1': 86, 'n_units_l2': 254, 'n_units_l3': 445, 'dropout': 0.11759201799075636, 'lr': 0.00011091662570733259, 'batch_size': 32, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:15:43,818] Trial 23 finished with values: [-0.9486666666666667, 31.216447830200195, 344245.0] and parameters: {'model_type': 'mlp', 'n_layers': 1, 'n_units_l0': 433, 'dropout': 0.04113167803355483, 'lr': 0.0017687205458975597, 'batch_size': 64, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:16:15,704] Trial 24 finished with values: [-0.9478333333333333, 30.848151922225952, 111797.0] and parameters: {'model_type': 'mlp', 'n_layers': 3, 'n_units_l0': 102, 'n_units_l1': 135, 'n_units_l2': 122, 'dropout': 0.4397875880404951, 'lr': 0.004256544333246553, 'batch_size': 64, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:18:19,622] Trial 25 finished with values: [-0.9298333333333333, 121.87364864349365, 4382345.0] and parameters: {'model_type': 'cnn', 'base_channels': 64, 'num_conv_layers': 3, 'fc_units': 349, 'dropout': 0.28555968831343853, 'lr': 0.00021817885629297224, 'batch_size': 64, 'optimizer': 'sgd'}.\n",
      "[I 2025-08-30 01:19:28,819] Trial 26 finished with values: [-0.9826666666666667, 67.76071572303772, 1156402.0] and parameters: {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 1, 'fc_units': 184, 'dropout': 0.35412053009804056, 'lr': 0.0016744447886186346, 'batch_size': 128, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:20:06,877] Trial 27 finished with values: [-0.8605, 37.04671502113342, 508016.0] and parameters: {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 510, 'n_units_l1': 158, 'n_units_l2': 98, 'n_units_l3': 104, 'dropout': 0.2542598829764025, 'lr': 0.011417431442464992, 'batch_size': 64, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:21:08,435] Trial 28 finished with values: [-0.9811666666666666, 60.158801317214966, 1517024.0] and parameters: {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 1, 'fc_units': 482, 'dropout': 0.0460595632919813, 'lr': 0.0077768748894823155, 'batch_size': 128, 'optimizer': 'adam'}.\n",
      "[I 2025-08-30 01:21:41,398] Trial 29 finished with values: [-0.8936666666666667, 31.97166085243225, 186297.0] and parameters: {'model_type': 'mlp', 'n_layers': 2, 'n_units_l0': 171, 'n_units_l1': 286, 'dropout': 0.086295237435773, 'lr': 0.018348739393937816, 'batch_size': 128, 'optimizer': 'adam'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fronteira de Pareto encontrada (objetivos: -acc, time(s), params):\n",
      "[-0.973, 33.15312886238098, 380020.0] {'model_type': 'mlp', 'n_layers': 1, 'n_units_l0': 478, 'dropout': 0.00799212280636924, 'lr': 0.008718214465614169, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "[-0.9751666666666666, 42.369699001312256, 211019.0] {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 2, 'fc_units': 67, 'dropout': 0.048199285791166835, 'lr': 0.0002869529650300838, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "[-0.9846666666666667, 44.468268394470215, 613835.0] {'model_type': 'cnn', 'base_channels': 16, 'num_conv_layers': 2, 'fc_units': 195, 'dropout': 0.14128024841085507, 'lr': 0.03108445617977969, 'batch_size': 128, 'optimizer': 'sgd'}\n",
      "[-0.9676666666666667, 38.2529456615448, 264791.0] {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 77, 'n_units_l1': 386, 'n_units_l2': 208, 'n_units_l3': 428, 'dropout': 0.06558288123757805, 'lr': 0.0002782484083297675, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "[-0.9848333333333333, 63.15505576133728, 1187817.0] {'model_type': 'cnn', 'base_channels': 32, 'num_conv_layers': 1, 'fc_units': 189, 'dropout': 0.30099354796525535, 'lr': 0.06446709015350537, 'batch_size': 128, 'optimizer': 'sgd'}\n",
      "[-0.9611666666666666, 35.866156339645386, 151451.0] {'model_type': 'mlp', 'n_layers': 4, 'n_units_l0': 84, 'n_units_l1': 156, 'n_units_l2': 123, 'n_units_l3': 395, 'dropout': 0.22566540796955625, 'lr': 0.0007050544388673726, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "[-0.9735, 31.6168794631958, 408120.0] {'model_type': 'mlp', 'n_layers': 2, 'n_units_l0': 394, 'n_units_l1': 244, 'dropout': 0.36210503020131196, 'lr': 0.03314067991346989, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "[-0.9486666666666667, 31.216447830200195, 344245.0] {'model_type': 'mlp', 'n_layers': 1, 'n_units_l0': 433, 'dropout': 0.04113167803355483, 'lr': 0.0017687205458975597, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "[-0.9478333333333333, 30.848151922225952, 111797.0] {'model_type': 'mlp', 'n_layers': 3, 'n_units_l0': 102, 'n_units_l1': 135, 'n_units_l2': 122, 'dropout': 0.4397875880404951, 'lr': 0.004256544333246553, 'batch_size': 64, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--mode', choices=['pareto', 'weighted'], default='pareto')\n",
    "parser.add_argument('--dataset', choices=['mnist', 'cifar10'], default='mnist')\n",
    "parser.add_argument('--n-trials', type=int, dest='n_trials', default=30)\n",
    "parser.add_argument('--epochs-per-trial', type=int, dest='epochs_per_trial', default=3)\n",
    "parser.add_argument('--max-time-hint', type=float, dest='max_time_hint', default=200.0)\n",
    "parser.add_argument('--max-params-hint', type=float, dest='max_params_hint', default=5e6)\n",
    "parser.add_argument('--w-acc', type=float, dest='w_acc', default=0.6)\n",
    "parser.add_argument('--w-time', type=float, dest='w_time', default=0.2)\n",
    "parser.add_argument('--w-params', type=float, dest='w_params', default=0.2)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "run_search(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
